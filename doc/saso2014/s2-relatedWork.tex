%!TEX root = main.tex
\section{Related Work}\label{s:related}
%Traditionally a subfield of distributed artificial intelligence, {\em distributed problem solving} is the use of multiple, semi-autonomous, and cooperating agents to solve a problem~\cite{weiss1999multiagent}.  Occasionally, a distinction is drawn between decomposition/distribution approaches, and those that rely on autonomous interactions among agents, known as multi-agent systems (MAS)~\cite{panait2005cooperative}.  The task of controlling the formation of a group of agents has been examined from different perspectives, including graph-stability, switching hierarchical control strategies, adaptive gradient climbing, and others~\cite{cassandras2005sensor}.  Here, instead of {\em engineering} control algorithms for the movement of agents, we employ neuroevolution to automatically {\em discover} controllers for a mobile network.
%
%In the broader context of MAS, the taxonomy provided by Panait and Luke~\cite{panait2005cooperative} places our study in the {\em team learning} category, where a single evolving individual encodes the behavior for the entire team (mobile network, in this case).  Moreover, the agents in this study engage in {\em direct communication} through message-passing, and no mechanism for indirect communication (e.g., stigmergy) is provided.  Finally, the scenario that we have selected for study is related to {\em cooperative target observation}, where a group of agents is tasked with collective observation of a target.  The specifics of our scenario will be explained in more detail in \CalloutSection{s:methods}.
%
%Within evolutionary computation, numerous techniques have been proposed to evolve cooperative teams that solve tasks. Waibel, Keller, and Floreano survey the work done in this area~\cite{waibel2009genetic}. Their classification highlights whether the group is homogeneous or heterogeneous and whether selection is performed at the level of the individual or team.  Additionally, they compare the performance of four types of teams: (1) homogeneous teams using individual selection; (2) homogeneous teams using group selection; (3) heterogeneous teams using individual selection, and (4) heterogeneous teams using group selection, on four cooperative tasks. Their results indicate that the genetic composition of groups and level of selection are key factors in evolving groups that perform cooperative tasks, and in general, find that homogeneous teams, as used here, tend to outperform other approaches.
%
%Neuroevolution is a kind of evolutionary algorithm that evolves ANNs.  {\neat} (NeuroEvolution of Augmenting Topologies)~\cite{stanley2002evolving}, described in more detail in \CalloutSection{s:methods}, has previously been used to evolve teams of agents through real-time interaction with a player, where each agent was controlled by an instance of an evolved neural network~\cite{stanley2005real}.  Neuroevolution has also produced adaptive teams, where agents with identical neural networks nonetheless exhibit different behaviors~\cite{bryant2003neuroevolution}.  Our study leverages {\neat} to address problems in the control of MANETs.
%
%Quint\~{a}o, Nakamura, and Mateus~\cite{quintao2005evolutionary} have studied dynamic coverage problems, and used an evolutionary algorithm to optimize the coverage of sensors set in fixed locations.  Hauert, Zufferey, and Floreano~\cite{hauert2009evolved} have also studied the use of a neural network controller for unmanned aerial vehicles (UAVs), where the ANN was evolved via a genetic algorithm.  Here, the UAVs were to establish and maintain a multi-hop communications link between a base station and a target without global or agent-relative positioning information.  Finally, D'Ambrosio {\etal}~\cite{dambrosio2010evolving} investigated the use of derivatives of {\neat} on a coverage-based problem, where agents were able to sense the boundaries of their environment, but were not able to sense other agents.  In the study presented here, we investigate the control of agents that are able to sense their positions in an open environment, but yet must coordinate to solve a coverage-related problem.
%
%In a previous study, we used a variety of different neuroevolutionary approaches to discover neural network controllers for nodes in a MANET~\cite{knoester2010neuroevolution}.  The main result of our prior study was that, regardless of the specific neuroevolutionary approach, the difficulty of controlling the network increased with the number of nodes.  In the study presented here, we again use neuroevolution to discover controllers for a MANET.  However, here we focus on one neuroevolutionary system, {\neat}, and propose solutions to three different aspects of this problem that were previously found to be challenging: network stability, self-organization, and scalability.
%
%
%%here we propose three characteristics that should be exhibited by large-scale systems:  First, the system must be {\em predictable}, which is to say that we as engineers should have confidence that the behavior of the system matches our expectation.  Second, the system must be {\em self-organizing} -- It cannot rely on the presence (or correct operation) of a central coordinator.  Finally, the system must be {\em scalable}.  Though self-organization and scalability are often correlated with each other in nature, in this study we treat them as separate aspects of behavior.  The question we address in this study is then, ``How can we discover behaviors distributed systems that are predictable, self-organizing and scalable?''
%
%%Specifically, we evaluated multiple variations of three different neuroevolutionary systems ({\neat}~\cite{stanley2002evolving}, {\hyperneat}~\cite{stanley2009a-hypercube-based}, and {\multiagent}~\cite{dambrosio2008generative}) on a coverage problem, where the agents were required to distribute themselves on a grid while maintaining network connectivity.  Each of these systems was used to evolve one or more artificial neural networks (ANNs), which were used as controllers for both the movement and communication behavior of agents within the network.  This problem thus includes not only a functional component (i.e., ``spread out to cover a region''), but also a non-functional component related to the topology of the network.  Agents were provided with simulated radios, and were able to broadcast to their neighbors within a limited range.  Whether agents were able to communicate with each other was defined by whether a neighbor is transmitting and also by distance between individuals.
