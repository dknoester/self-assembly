%!TEX root = main.tex
\section{Introduction}\label{s:intro}

Nature provides us with many examples of self-organizing systems, from inorganic X to the wondrously complex behavior of social organisms such as honeybees, ants, and even larger mammals~\cite{?}.  In addition to being self-organizing, many natural systems are also {\em self-adaptive}, where the agents within each system change their behavior over time, in response to environmental stimuli.  Learning is one such example of a self-adaptive behavior.  While many researchers have taken inspiration from self-organizing biological systems to develop self-organizing computational systems, few have demonstrated systems that are both SO and self-adaptive.  Indeed, it remains a challenge to show how SO and SA systems might be merged into a unified framework to enable us to engineer the next generation of large scale distributed computing systems.

To further our understanding of such systems, researchers have long relied upon ``simple'' mathematical models or simulations.  Among these model systems are the well-known {\em cellular automata}, in which cells in a typically grid-structured environment follow simple rules to update their state.  The well-known ``Game of Life''~\cite{conway} is one such example of a 2-dimensional elementary cellular automata.  The behavior of a typical CA can be completely described by a set of rules $\Phi$, which is simply a binary vector containing a single entry (the output state) for each of the possible states of a given cell's neighborhood.  Depending on the dimension of the CA and the radius of a cell's neighborhood, rule sets can be either very simple, or unimaginably large and complex.

Many different approaches to discovering the ruleset for a CA have been devised.  While some rely upon enumeration of all possible rulesets, others have employed various search techniques to discover rulesets that solve a given problem.  For example, Mitchell~\etal have demonstrated that genetic algorithms are capable of discovering 128-bit rulesets that solve the 1D, n=35, r=3 majority bit and synchronization problems.  Others, using different EAs, have shown interesting relationships between rulesets and CA topology~\cite{?}.  While these approaches to CAs have already shed light on many of the principles behind SO systems, they do not address systems that include an ability to self-adapt.

In this paper, we focus on cellular automata that {\em both} self-organize and self-adapt.  We use a novel evolutionary algorithm that is able to construct adaptable state machines to solve the CA bit-consensus problem.  We demonstrate that these state machines are able self-organize and solve the bit-consensus problem in 1-, 2- and 3-dimensional CAs in a scale-free manner.  Finally, we show that the addition of a global reinforcement signal dramatically improves the evolvability and performance of this system, and that such a signal confers a high degree of resilience to environmental perturbation.

The contributions of this work are as follows.  First, we present one method by which self-organizing and self-adaptive systems can be discovered.  Second, we demonstrate the effectiveness of this approach on 1-, 2-, and 3-dimensional cellular automata, and show that the solutions discovered by an evolutionary algorithm scale to CAs many times their evolved size.  Finally, we show howl the combination of an adaptive system with global reinforcement signals provides a high degree of resilience to environmental perturbation.  These results support the use of cellular automata based systems as a study system for exploring SASO principles, show one method by which self-adaptation can be included in self-organizing systems, and further strengthen the case for the use of evolutionary algorithms to discover SASO systems.